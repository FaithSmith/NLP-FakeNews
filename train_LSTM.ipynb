{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\33645\\\\Desktop\\\\projects\\\\kaggle\\\\FakeNews'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "pwd = os.getcwd()\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title              author  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', usecols=['title', 'author', 'text', 'label'])\n",
    "test = pd.read_csv('test.csv', usecols=['title', 'author', 'text'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.concat([train,test],axis='rows')\n",
    "df['comb']=df['author']+\" \"+df['title']     # Combined features \n",
    "test['comb']=df['author']+\" \"+df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5069"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Null values\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace na values\n",
    "df.fillna('unavailable',inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "test.fillna('unavailable',inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting indedependent variable and independent variables\n",
    "X = df.drop('label',axis=1)\n",
    "y = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20800"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make a copy in case I want to go back\n",
    "X_edited = X.copy()\n",
    "len(X_edited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20800"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#init a list to contain preprocessed text\n",
    "corpus = []\n",
    "st = PorterStemmer()\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i, title in enumerate(X_edited['comb']):\n",
    "    title_edited = re.sub('[^a-zA-Z]',' ', title)\n",
    "    title_edited_list = title_edited.lower().split()\n",
    "    title_words_stem = [st.stem(word) for word in title_edited_list if word not in stopwords.words('english')]\n",
    "    corpus.append(' '.join(title_words_stem))\n",
    "\n",
    "len(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5200"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#init a list to contain preprocessed text\n",
    "X_test = []\n",
    "st = PorterStemmer()\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i, title in enumerate(test['comb']):\n",
    "    title_edited = re.sub('[^a-zA-Z]',' ', title)\n",
    "    title_edited_list = title_edited.lower().split()\n",
    "    title_words_stem = [st.stem(word) for word in title_edited_list if word not in stopwords.words('english')]\n",
    "    X_test.append(' '.join(title_words_stem))\n",
    "\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'darrel lucu hous dem aid even see comey letter jason chaffetz tweet'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of preprocessed title\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[160, 627, 660, 262, 1206, 516, 1864, 393, 1093, 1312, 506, 704]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First step: One-hot Encode\n",
    "voc_size = 2000\n",
    "one_hot_repr = [one_hot(title, voc_size) for title in corpus]\n",
    "one_hot_X_test = [one_hot(title, voc_size) for title in X_test]\n",
    "#One example of one_hot_rep: we replace each word in the title by\n",
    "#its index in the vocabulary\n",
    "one_hot_repr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(lst) for lst in one_hot_repr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,  160,  627,  660,  262, 1206,  516, 1864,\n",
       "        393, 1093, 1312,  506,  704])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_length=60\n",
    "padded_docs=pad_sequences(one_hot_repr,padding='pre',maxlen=sentence_length)\n",
    "padded_docs_test = pad_sequences(one_hot_X_test,padding='pre',maxlen=sentence_length)\n",
    "padded_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 60, 50)            100000    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 100)               60400     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,501\n",
      "Trainable params: 160,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#embedding_vector_features\n",
    "output_dim=50\n",
    "input_dim = voc_size\n",
    "model=Sequential()\n",
    "model.add(Embedding(input_dim,output_dim,input_length=sentence_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=4)\n",
    "X_edited_bl, y_bl = sm.fit_resample(padded_docs, y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_edited_bl, y_bl, test_size=0.3, random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.0719 - val_accuracy: 0.9861\n",
      "Epoch 2/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.0733 - val_accuracy: 0.9872\n",
      "Epoch 3/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.0764 - val_accuracy: 0.9867\n",
      "Epoch 4/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0717 - val_accuracy: 0.9877\n",
      "Epoch 5/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0726 - val_accuracy: 0.9869\n",
      "Epoch 6/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0776 - val_accuracy: 0.9874\n",
      "Epoch 7/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0728 - val_accuracy: 0.9878\n",
      "Epoch 8/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0775 - val_accuracy: 0.9874\n",
      "Epoch 9/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0792 - val_accuracy: 0.9877\n",
      "Epoch 10/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0890 - val_accuracy: 0.9875\n",
      "Epoch 11/20\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0828 - val_accuracy: 0.9851\n",
      "Epoch 12/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0827 - val_accuracy: 0.9872\n",
      "Epoch 13/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0944 - val_accuracy: 0.9862\n",
      "Epoch 14/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0896 - val_accuracy: 0.9870\n",
      "Epoch 15/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0897 - val_accuracy: 0.9869\n",
      "Epoch 16/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0867 - val_accuracy: 0.9875\n",
      "Epoch 17/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0874 - val_accuracy: 0.9878\n",
      "Epoch 18/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0860 - val_accuracy: 0.9877\n",
      "Epoch 19/20\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0898 - val_accuracy: 0.9872\n",
      "Epoch 20/20\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0897 - val_accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2045d3603a0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=20,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sgd=tf.keras.optimizers.SGD(learning_rate=0.01, decay=1e-6,momentum=0.9, nesterov=True)\n",
    "rms = tf.keras.optimizers.RMSprop()\n",
    "nadam=tf.keras.optimizers.Nadam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Nadam\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 60, 50)            100000    \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 100)               60400     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,501\n",
      "Trainable params: 160,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "#embedding_vector_features\n",
    "output_dim=50\n",
    "input_dim = voc_size\n",
    "model2=Sequential()\n",
    "model2.add(Embedding(input_dim,output_dim,input_length=sentence_length))\n",
    "model2.add(LSTM(100))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(1,activation='sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.0730 - val_accuracy: 0.9832\n",
      "Epoch 2/10\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.0779 - val_accuracy: 0.9840\n",
      "Epoch 3/10\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0805 - val_accuracy: 0.9840\n",
      "Epoch 4/10\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.0842 - val_accuracy: 0.9845\n",
      "Epoch 5/10\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0877 - val_accuracy: 0.9838\n",
      "Epoch 6/10\n",
      "228/228 [==============================] - 11s 46ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0937 - val_accuracy: 0.9834\n",
      "Epoch 7/10\n",
      "228/228 [==============================] - 11s 46ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0930 - val_accuracy: 0.9837\n",
      "Epoch 8/10\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0963 - val_accuracy: 0.9827\n",
      "Epoch 9/10\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0944 - val_accuracy: 0.9834\n",
      "Epoch 10/10\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0973 - val_accuracy: 0.9835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2049a70ffd0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHOOSING THE THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutoff(fpr,tpr,thresholds):\n",
    "  difference = tpr-fpr\n",
    "  sorted_diff_thresh_inc = sorted(zip(difference,thresholds))\n",
    "  #return thresh giving the biggest diff\n",
    "  return sorted_diff_thresh_inc[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.6331223e-09, 2.2366070e-08, 6.0099425e-11, ..., 1.0864171e-05,\n",
       "       9.9994206e-01, 9.9998844e-01], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "import numpy as np\n",
    "y_pred_valid = model.predict(X_val)\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(padded_docs_test)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_val, y_pred_valid)\n",
    "fpr, tpr, threshold = roc_curve(y_val, y_pred_valid)\n",
    "thresh = cutoff(fpr, tpr, threshold)\n",
    "pred_train = pd.DataFrame()\n",
    "pred_train[\"label\"] = y_pred_train.ravel()\n",
    "pred_train[\"label\"] = np.where(pred_train[\"label\"] > float(thresh), 1, 0)\n",
    "\n",
    "pred_valid = pd.DataFrame()\n",
    "pred_valid[\"label\"] = y_pred_valid.ravel()\n",
    "pred_valid[\"label\"] = np.where(pred_valid[\"label\"] > float(thresh), 1, 0)\n",
    "\n",
    "pred_test = pd.DataFrame()\n",
    "pred_test['label'] = y_pred_test.ravel()\n",
    "pred_test['label'] = np.where(pred_test['label'] > float(thresh), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990396071377126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9883142971974825"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_train, pred_train[\"label\"],average='macro'))\n",
    "f1_score(y_val, pred_valid[\"label\"],average='macro')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ec22e5716d6b3a8875c213e3bd6d001645199f4bac79e779b5e79c0e3d5448e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('fast': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
